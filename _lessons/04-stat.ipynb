{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "layout: page\n",
    "title: Estatística Básica\n",
    "nav_order: 4\n",
    "has_toc: true\n",
    "---\n",
    "\n",
    "# Estatística Básica\n",
    "{: .no_toc .mb-2 }\n",
    "\n",
    "Um breve resumo de alguns comandos python.\n",
    "{: .fs-6 .fw-300 }\n",
    "\n",
    "{: .no_toc .text-delta }\n",
    "Objetivos\n",
    "\n",
    "1. Entender como sumarizar dados.\n",
    "1. Relembrar tendências centrais de dados.\n",
    "1. Mais importante, entender as falácias de sumarização de dados.\n",
    "\n",
    "{: .no_toc .text-delta }\n",
    "Resultado Esperado\n",
    "\n",
    "1. Entendimento de médias, medianas, desvio padrão e quartis.\n",
    "1. Entendimento de propriedades das médias\n",
    "\n",
    "---\n",
    "**Sumário**\n",
    "1. TOC\n",
    "{:toc}\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf8\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Para evitar a confusão da aula passada, colocando alguns defaults!\n",
    "plt.rcParams['axes.labelsize']  = 20\n",
    "plt.rcParams['axes.titlesize']  = 20\n",
    "plt.rcParams['legend.fontsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 20\n",
    "plt.rcParams['ytick.labelsize'] = 20\n",
    "plt.rcParams['lines.linewidth'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-colorblind')\n",
    "plt.ion()\n",
    "plt.rcParams['figure.figsize']  = (18, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def despine(ax=None):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    # Hide the right and top spines\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    # Only show ticks on the left and bottom spines\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.xaxis.set_ticks_position('bottom')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Introdução\n",
    "\n",
    "As estatísticas referem-se à matemática e técnicas com as quais entendemos os dados. É um campo rico e enorme, mais adequado a uma prateleira (ou sala) em uma biblioteca do que a uma aula de um curso. De qualquer forma, nosso curso de ICD tem um viés estatístico. Portanto, vamos iniciar do mais básico que é a sumarização de bases de dados com médias, medianas e desvios.\n",
    "\n",
    "## Descrevendo uma coluna bem comportada dados\n",
    "\n",
    "Vamos lembrar um pouco de histogramas e falar sobre CDF empírica. Para tal, vamos entender a duração das músicas sa Billboard. Na tabela abaixo, temos as músicas mais populares (semanalmente) de 2000 até 2018. Vamos focar apenas no id único (spotify id) das mesmas. Como algumas músicas ocorrem mais de uma vez, vamos também filtrar as duplicatas.\n",
    "\n",
    "**Sempre visualize seus dados**. Como primeira abordagem, plote seus dados. Duas ideias inicias: PDF e CDF!\n",
    "\n",
    "Observe que aqui indico um `na_values`, para falar de missing data (aula passada). Além do mais, faço um `dropna`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lendo os dados.\n",
    "df = pd.read_csv('https://media.githubusercontent.com/media/icd-ufmg/material/master/aulas/05-Tendencias-Centrais/billboard_2000_2018_spotify_lyrics.csv',\n",
    "                 encoding='iso-8859-1', na_values='unknown')\n",
    "# 2. Removendo na\n",
    "df = df[['date', 'artist', 'title', 'duration_ms', 'spotify_id', 'lyrics']]\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos observar quantas músicas temos!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = df['duration_ms']\n",
    "dur.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remover duplicatas, uma músicas pode aparecer mais de uma vez na base!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dur = dur.drop_duplicates()\n",
    "dur.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converter a duração para minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dur / (1000 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, o histograma!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, bins=20, edgecolor='k')\n",
    "plt.xlabel('Duração em minutos')\n",
    "plt.ylabel('Frequência.')\n",
    "despine(plt.gca())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer um código simples para montar uma CDF. A função de nome CDF (em inglês de Cumulative Distribution Function) é igual à probabilidade de que a variável aleatória X assuma um valor inferior ou igual a determinado x. Note que, via de regra, para cada x, a função CDF assumirá um valor diferente. Para estimar uma CDF de forma empírica, realizamos os seguintes passos:\n",
    "\n",
    "1. Ordene os dados `x = np.sort(data)`\n",
    "1. Conte quantos pontos menor do que `x[i]` existem para cada `i`\n",
    "    1. Para isto, vamos montar um vetor `y = np.arange(len(data))`. y é um contagem cumulativa.\n",
    "    1. Note que y conta quantos pontos existe até um ponto i, i.e., `y[i] = #pts < x[i]`.\n",
    "1. Normalize `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    x = np.sort(data)\n",
    "    count = np.arange(len(data))\n",
    "    y = count.cumsum()\n",
    "    y = y / y.max()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ecdf(data)\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Duração em minutos')\n",
    "plt.ylabel('$P(X \\leq x)$')\n",
    "despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca **statsmodels** tem a mesma função. É o maior import que faço na minha vida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "ecdf = ECDF(data)\n",
    "x = ecdf.x\n",
    "y = ecdf.y\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Duração em minutos')\n",
    "plt.ylabel('$P(X \\leq x)$')\n",
    "despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tendências Centrais\n",
    "\n",
    "Agora, vamos sumarizar os dados das músicas. Uma descrição óbvia de qualquer conjunto $x_1, x_2, ..., x_n$ de dados é simplesmente os dados em si:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um conjunto de dados pequeno o suficiente, isso pode até ser a melhor descrição. Mas, para um conjunto de dados maior, isso é difícil e provavelmente opaco (temos alguns milhares de números). Por esse motivo, usamos estatísticas para destilar e comunicar características relevantes dos nossos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infelizmente, este gráfico ainda é muito difícil de explicar em conversas informais. Então você pode começar a gerar algumas estatísticas. Provavelmente, a estatística mais simples é o número de pontos de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = len(data)\n",
    "print(\"numero de pontos:\", num_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um vetor numpy tem diferentes atributos para pegar a dimensão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape indica o tamanho para cada dimensão, em uma matriz teríamos dois valores.\n",
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note como os dados originais tem 5 colunas\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você provavelmente também está interessado no maior e menor valor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_value = max(data) \n",
    "smallest_value = min(data)\n",
    "print(\"maximo: \", largest_value, \"\\nminimo: \", smallest_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou, usando numpy / pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esses são apenas casos especiais quando queremos saber os valores em posições específicas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values = np.sort(data)\n",
    "smallest_value = sorted_values[0] \n",
    "second_smallest_value = sorted_values[1] \n",
    "second_largest_value = sorted_values[-2] \n",
    "print(\"menor valor: \", smallest_value)\n",
    "print(\"segundo menor valor: \", second_smallest_value)\n",
    "print(\"segundo maior valor: \", second_largest_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando os top 20 valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_values[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Média\n",
    "\n",
    "Normalmente, queremos saber onde nossos dados estão centralizados. Para chegar em tal resultado, usamos a média (a soma dos dados dividida pelo número de elementos. A mesma está definida abaixo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\bar {x}}={\\frac {1}{n}}\\left(\\sum _{i=1}^{n}{x_{i}}\\right)={\\frac {x_{1}+x_{2}+\\cdots +x_{n}}{n}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um código simples para o cálculo da média seria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(x):\n",
    "    return sum(x) / len(x)\n",
    "\n",
    "print(\"media: \", mean(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou de forma equivalente, podemos usar x.mean() caso x seja um vetor `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou ainda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, bins=20, label='PDF', edgecolor='k')\n",
    "plt.vlines(data.mean(), 0, 1900, label='Mean', edgecolor='k')\n",
    "plt.xlabel('Duração em minutos')\n",
    "plt.ylabel('P(X = x)')\n",
    "plt.legend()\n",
    "despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediana\n",
    "\n",
    "Se você tiver dois pontos de dados (ou *data points*), a média é simplesmente o ponto intermediário entre eles. À medida que você adiciona mais pontos, a média muda, mas sempre depende do valor de cada ponto.\n",
    "\n",
    "Às vezes, também estaremos interessados na mediana, que é o valor intermediário (se o número de pontos de dados for ímpar) ou a média dos dois valores intermediários (se o número de pontos de dados for par).\n",
    "\n",
    "Por exemplo, se temos cinco pontos de dados em um vetor ordenado `x`, a mediana é `x[5 // 2]`  ou `x[2]`. Se tivermos seis pontos de dados, calculamos a média entre `x[2]` (o terceiro ponto) e `x[3]` (o quarto ponto).\n",
    "\n",
    "Observe que, ao contrário da média, a mediana não depende de todos os valores dos seus dados. Por exemplo, se você tornar o maior ponto maior (ou o menor ponto menor), os pontos do meio permanecem inalterados, o que significa que a mediana também.\n",
    "\n",
    "A função mediana é um pouco mais complicada do que você poderia esperar, principalmente por causa do caso \"par\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(v):\n",
    "    \"\"\"encontra o valor mais intermediario de v\"\"\"\n",
    "    n = len(v)\n",
    "    sorted_v = list(sorted(v))\n",
    "    midpoint = n // 2 # // eh a divisao inteira\n",
    "    \n",
    "    if n % 2 == 1:\n",
    "        # se impar, retorna o valor do meio\n",
    "        return sorted_v[midpoint]\n",
    "    else:\n",
    "        # se par, retorna a media dos dois valores intermediarios\n",
    "        lo = midpoint - 1\n",
    "        hi = midpoint\n",
    "        return (sorted_v[lo] + sorted_v[hi]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_v2(v):\n",
    "    n = len(v)\n",
    "    sorted_v = sorted(v)\n",
    "    return (sorted_v[math.floor((n-1)/2)] + sorted_v[math.ceil((n-1)/2)])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7, 8, 9]\n",
    "print(\"mediana de a = \", median(a))\n",
    "print(\"mediana de b = \", median(b))\n",
    "\n",
    "print(\"mediana da duração das músicas:\", median(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, no âmbito da matéria é esperado que você entenda os códigos acima. Existem forma de encontrar medianas até mais rápido, usando o algoritmo quickselect. Na prática, podemos fazer uso do `median` do numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data, bins=20, label='Freq.', edgecolor='k')\n",
    "plt.vlines(data.mean(), 0, 1900, label='Mean', edgecolor='k')\n",
    "plt.vlines(data.median(), 0, 1900, linestyles='--', label='Median', color='red')\n",
    "plt.xlabel('Duração em minutos')\n",
    "plt.ylabel('Freq')\n",
    "plt.legend()\n",
    "despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplot\n",
    "\n",
    "Vamos agora observar o boxplot das durações. Um boxplot representa a variação de dados observados de uma variável numérica por meio de quartis.\n",
    "\n",
    "1. primeiro quartil (designado por Q1/4) = quartil inferior = é o valor aos 25% da amostra ordenada = 25º percentil\n",
    "1. segundo quartil (designado por Q2/4) = mediana = é o valor até ao qual se encontra 50% da amostra ordenada = 50º percentil, ou 5º decil.\n",
    "1. terceiro quartil (designado por Q3/4) = quartil superior = valor a partir do qual se encontram 25% dos valores mais elevados = valor aos 75% da amostra ordenada = 75º percentil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# com whis=[5, 95] eu mostro P(X < x) = 5% e P(X > x) = 95%\n",
    "plt.boxplot([data], sym='', vert=True, whis=[5, 95])\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels(['Duração'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente, a média é mais simples de calcular e varia suavemente conforme nossos dados são alterados. Se tivermos `n` pontos de dados e um deles aumentar em alguma quantidade pequena `e`, então necessariamente a média aumentará em `e/n`. (Isso torna a média passível de todo tipo de truque de cálculo.) No entanto, para encontrar a mediana, temos que ordenar nossos dados. E alterar um dos nossos pontos de dados em uma pequena quantidade `e` pode aumentar a mediana por `e`, por algum número menor que `e` ou não a modificar de qualquer forma (dependendo do resto dos dados).\n",
    "\n",
    "**Observação:** Existem, de fato, truques não óbvios para calcular eficientemente medianas sem ordenar os dados. No entanto, tais truques estão além do escopo deste curso, portanto, vamos ordernar os dados quando precisarmos calcular a mediana.\n",
    "\n",
    "Ao mesmo tempo, a média é muito sensível a valores discrepantes (*outliers*) em nossos dados. Se a música mais longa fosse de mais de 1h (https://www.youtube.com/watch?v=10SnNfxjAI8), a média seria afetada. Em contraprtida, a mediana permaneceria a mesma. Se os valores discrepantes forem, provavelmente, dados incorretos (ou, de outro modo, não representativos de qualquer fenômeno que estamos tentando entender), a média poderá, às vezes, nos fornecer uma imagem enganosa. Por exemplo, a história é frequentemente contada que em meados da década de 1980, a graduação da Universidade da Carolina do Norte com a maior média de salário inicial era a geografia. A razão disso? A estrela da NBA (e *outlier*) Michael Jordan formou-se em geografia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data.copy()\n",
    "# Vamos supor uma música gigantesca!\n",
    "data_new = data_new.append(pd.Series([9999]))\n",
    "print(data.mean(), data_new.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe como a mediana se mantém!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.median(), data_new.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma generalização da mediana é o quantil, que representa o menor valor maior que um certo percentual dos dados (A mediana representa o valor maior que 50% dos dados.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile(x, p):\n",
    "    \"\"\"retorna o pth-percentil em x\"\"\"\n",
    "    p_index = int(p * len(x))\n",
    "    return sorted(x)[p_index]\n",
    "\n",
    "\n",
    "print(\"quantil 10: \", quantile(data, 0.10))\n",
    "print(\"quantil 25: \", quantile(data,0.25))\n",
    "print(\"quantil 75: \", quantile(data,0.75))\n",
    "print(\"quantil 90: \", quantile(data,0.90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra medida para tendência central dos dados é a moda, que é(são) o(s) valor(es) mais comum(ns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(x):\n",
    "    \"\"\"retorna uma lista, pois os dados podem ter mais de uma moda\"\"\"\n",
    "    x = np.asanyarray(x)\n",
    "    unique, counts = np.unique(x, return_counts=True)\n",
    "    max_count = counts.max()\n",
    "    return unique[counts == max_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 2, 4, 4]\n",
    "print(\"moda de a: \", mode(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que para casos contínuos como as músicas a moda faz pouco sentido. Temos que arredondar os mesmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"moda das músicas em minutos truncadas: \",\n",
    "      mode(np.round(data, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformadas\n",
    "\n",
    "Quando usarmos esses descritores para descrever dados, devemos ter muito cuidado. Considere, por exemplo, dados que possuem uma \"cauda pesada\", como uma amostra da [distribuição de Pareto](https://en.wikipedia.org/wiki/Pareto_distribution). Um bom exemplo de dados deste tipo é a frequência de palavras nas letras de cada música.\n",
    "Vamos construir uma nova série com tal informação!\n",
    "\n",
    "Note que temos que ter cuidado com os dados.\n",
    "1. Músicas se repetem na billboard.\n",
    "2. Temos que limpar acentos e pontuação. Para tal, expressões regulares são úteis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import re\n",
    "\n",
    "counter = Counter()\n",
    "for row in df['lyrics'].unique(): # Com unique eu filtro letras iguais.\n",
    "    # o código re.sub(r'[^\\w\\s]', '', row.lower()) tira todos os acentos!\n",
    "    words = re.sub(r'[^\\w\\s]', '', row.lower()).strip().split()\n",
    "    counter.update(set(words))\n",
    "\n",
    "palavras = pd.Series(counter)\n",
    "palavras.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos plotar o histograma dos dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(palavras, bins=100, edgecolor='k')\n",
    "plt.xlabel('Popularidade da palavra')\n",
    "plt.ylabel('Freq.')\n",
    "despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.logspace(np.log10(palavras.min()), np.log10(palavras.max()))\n",
    "plt.hist(palavras, bins=bins, edgecolor='k')\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('Popularidade da palavra')\n",
    "plt.ylabel('Freq.')\n",
    "despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que a grande maioria dos valores é menor que $10$, mas existe uma quantidade significativa de valores na casa das centenas e até dos milhares. \n",
    "\n",
    "Nesse caso, qual é o melhor descritor para esses dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mean(palavras),\n",
    "      median(palavras),\n",
    "      max(palavras),\n",
    "      mode(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao que parece, todos eles são importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variância e Desvio Padrão\n",
    "\n",
    "Dispersão refere-se a medidas de como se espalham nossos dados. Normalmente, são estatísticas para as quais valores próximos de zero significam que os dados não se espalham de forma alguma e para as quais grandes valores (seja lá o que isso signifique) significam que os dados estão muito dispersos. Por exemplo, uma medida muito simples é o intervalo (ou *range*), que é apenas a diferença entre os elementos maiores e menores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"range\" já significa algo em Python, então vamos usar outro nome\n",
    "def data_range(x):\n",
    "    return max(x) - min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"range: \", data_range(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O intervalo é zero precisamente quando `max` e `min` são iguais, o que só pode acontecer se os elementos de `x` forem todos iguais, o que significa que os dados são tão similares (ou não dispersos) quanto possível. Por outro lado, se o intervalo for grande, o `max` é muito maior que o `min` e os dados estão mais espalhados.\n",
    "\n",
    "Como a mediana, o intervalo não depende realmente de todo o conjunto de dados. Um conjunto de dados cujos pontos são todos 0 ou 100 tem o mesmo intervalo que um conjunto de dados cujos valores são 0, 100 e muitos 50s. Mas parece que o primeiro conjunto de dados \"deveria\" estar mais espalhado, certo?\n",
    "\n",
    "Uma medida mais complexa de dispersão é a variância $s^2$. Quando a variância da população é estimada usando $n$ amostras aleatórias $x_1, x_2, ..., x_n$ a fórmula seguinte é um estimador não enviesado:\n",
    "\n",
    "$$s^{2}={\\frac {1}{n-1}}\\sum _{{i=1}}^{n}\\left(x_{i}-\\overline {x}\\right)^{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código abaixo faz o mesmo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def de_mean(x):\n",
    "    \"\"\"translada x subtraindo sua média (então o resultado tem média 0)\"\"\"\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "\n",
    "def variance(x):\n",
    "    \"\"\"assume que x tem pelo menos dois elementos\"\"\"\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    deviations = np.array(deviations) #vamos usar numpy muito de agora em diante\n",
    "    return np.sum(deviations ** 2) / (n-1)\n",
    "    #voce pode usar a funcao que implementamos anteriormente:\n",
    "    #return sum_of_squares(deviations) / (n - 1)\n",
    "\n",
    "print(\"variancia: \", variance(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira observação é o uso do módulo `numpy`. A partir de agora vamos usar muito esse módulo, que contém diversas operações sobre listas, que são implementadas de forma eficiente.\n",
    "\n",
    "Na aula passada, implementamos a função `sum_of_squares`. Para fazer a mesma coisa, e de forma mais rápida, podemos usar a função `sum` do `numpy` e o operador `**` para elevar todos os elementos de uma lista a uma dada potência, nesse caso, `2`. Note que antes de usar executar essas operações, é necessário converter a lista para um *array* do `numpy`.\n",
    "\n",
    "Segundo, parece que a variância é quase o desvio médio da média, exceto pelo fato de estarmos dividindo por `n-1` em vez de `n`. De fato, quando estamos lidando com uma amostra de uma população maior, $\\overline {x}$ é apenas uma estimativa da média real, o que significa que, em média $\\left(x_{i}-\\overline {x}\\right)^{2}$ é uma subestimativa do desvio ao quadrado de $x_i$ em relação à média. Por isso que nós dividimos por `n-1` ao invés de `n`. Para mais informações, consulte o [Wikipedia](https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation).\n",
    "\n",
    "Agora, quaisquer que sejam as unidades em que nossos dados estão (por exemplo, \"# de amigos\"), todas as nossas medidas de tendência central estão nessa mesma unidade. O intervalo será similarmente nessa mesma unidade. A variância, por outro lado, tem unidades que são o quadrado das unidades originais (por exemplo, \" # de amigos ao quadrado\"). Como pode ser difícil entender essa medida, muitas vezes olhamos para o desvio padrão $s = \\sqrt{s^2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"desvio padrao: \", np.std(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto o intervalo quanto o desvio padrão têm o mesmo problema discrepante que vimos anteriormente para a média. Usando o mesmo exemplo, se nosso usuário mais amigável tivesse `2000` amigos, o desvio padrão seria muito maior somente por causa desse usuário. Uma alternativa mais robusta calcula a diferença entre o valor do 75º e do 25º percentil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interquartile_range(x):\n",
    "    return quantile(x, 0.75) - quantile(x, 0.25)\n",
    "\n",
    "print(\"intervalo interquartil:\", interquartile_range(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa medida é muito pouco afetada por *outliers*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dispersão para a duração das músicas:\")\n",
    "print(\"Intervalo:\", data_range(data))\n",
    "print(\"Variância:\", np.var(data))\n",
    "print(\"Desvio padrão:\", np.std(data))\n",
    "print(\"IQR:\", interquartile_range(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medidas de dispersão para dados com \"cauda pesada\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dispersão para as palavras:\")\n",
    "print(\"Intervalo:\", data_range(palavras))\n",
    "print(\"Variância:\", np.var(palavras))\n",
    "print(\"Desvio padrão:\", np.std(palavras))\n",
    "print(\"IQR:\", interquartile_range(palavras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, tudo isto poderia ser feito com uma única chamada pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vamos ver uma correlação entre duração e número de palavras! Explique o código abaixo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letra_e_musica = df[['duration_ms', 'lyrics']].drop_duplicates()\n",
    "letra_e_musica['duration_min'] = letra_e_musica['duration_ms'] / (60 * 1000)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for indice, row in letra_e_musica.iterrows():\n",
    "    words = re.sub(r'[^\\w\\s]', '', row['lyrics'].lower()).strip().split()\n",
    "    x.append(len(words))\n",
    "    y.append(row['duration_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.xlabel('Número de palavras na letra')\n",
    "plt.ylabel('Duração');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
